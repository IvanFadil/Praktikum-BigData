{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e3dd6a-51bc-40ef-906a-00f8327fc69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00336619-6aa7-42b3-a4b4-fcdff9cd0f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/16 22:34:39 WARN Utils: Your hostname, ivan resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/11/16 22:34:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/16 22:34:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/16 22:34:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"SparkDateTime\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b27aa3-ec42-4620-95f6-8322a9061d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"items_bought.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6d81e4-3922-45cc-9dd9-83a7685a8728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+----------+------------+\n",
      "|      date|item_name|item_price|quantity|tax_amount|total_amount|\n",
      "+----------+---------+----------+--------+----------+------------+\n",
      "|11-10-2018|     Beer|     110.5|       2|     53.04|      163.54|\n",
      "|14-02-2018|   Whisky|    1250.0|       1|     300.0|      1550.0|\n",
      "|23-03-2020|   Whisky|    1300.5|       2|    624.24|     1924.74|\n",
      "+----------+---------+----------+--------+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9667cd83-c845-4baa-b7b9-d381321b2596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema with date as string datatype\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- item_price: double (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- tax_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema with date as string datatype\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670b9291-b723-4bb6-b501-b072d1fe1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime, to_date #importing necessary functions to convert date string to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0aeb63-f5c4-48cf-990d-f040cb301841",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = df.withColumn('formatted_date',to_date(unix_timestamp(df['date'],'dd-MM-yyyy').cast('timestamp')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d66896c7-de56-42e9-af36-e2490aa54c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema with date column string datatype converted to date datatype\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- item_price: double (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- tax_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- formatted_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema with date column string datatype converted to date datatype\")\n",
    "\n",
    "updated_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f9a349a-f54e-4327-9837-f1e5852484af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after dropping the date column which was of stringtype\n",
      "+---------+----------+--------+----------+------------+--------------+\n",
      "|item_name|item_price|quantity|tax_amount|total_amount|formatted_date|\n",
      "+---------+----------+--------+----------+------------+--------------+\n",
      "|     Beer|     110.5|       2|     53.04|      163.54|    2018-10-11|\n",
      "|   Whisky|    1250.0|       1|     300.0|      1550.0|    2018-02-14|\n",
      "+---------+----------+--------+----------+------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data after dropping the date column which was of stringtype\")\n",
    "updated_df=updated_df.drop(\"date\") #dropping the date column with string type\n",
    "updated_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27318796-2d60-45b9-8670-e0c974f186e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import weekofyear,dayofmonth,month,year,date_format #extracting data from dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea2c489-4a81-4f16-b847-f53031e3c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extraction from dates\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Extraction from dates\")\n",
    "final_df = updated_df.select(updated_df[\"item_name\"],\n",
    "weekofyear(updated_df[\"formatted_date\"]).alias(\"week_number\"),\n",
    "dayofmonth(updated_df[\"formatted_date\"]).alias(\"day_number\"),\n",
    "month(updated_df[\"formatted_date\"]).alias(\"month\"),\n",
    "year(updated_df[\"formatted_date\"]).alias(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb53fb12-26cd-4d9c-81b2-1bc2f17393ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+-----+----+\n",
      "|item_name|week_number|day_number|month|year|\n",
      "+---------+-----------+----------+-----+----+\n",
      "|     Beer|         41|        11|   10|2018|\n",
      "|   Whisky|          7|        14|    2|2018|\n",
      "|   Whisky|         13|        23|    3|2020|\n",
      "+---------+-----------+----------+-----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(3)\n",
    "date_string_value = updated_df.select(df[\"item_name\"],date_format(updated_df[\"formatted_date\"],'MM/dd/yyyy')) #converting date type to a different date format string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52da1754-c038-4e39-be6f-7e2990b5318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------------------------+\n",
      "|item_name|date_format(formatted_date, MM/dd/yyyy)|\n",
      "+---------+---------------------------------------+\n",
      "|     Beer|                             10/11/2018|\n",
      "|   Whisky|                             02/14/2018|\n",
      "+---------+---------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_string_value.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a19c83c-f527-4106-a8a1-6ef94c1408c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usecase - Total amount of items purchased in that particular year\n"
     ]
    }
   ],
   "source": [
    "print(\"Usecase - Total amount of items purchased in that particular year\")\n",
    "final_format=final_df.groupBy(\"year\").sum().select([\"year\",\"sum(year)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccfd70a8-543e-40de-9972-6631b8c2c35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|year|Total Expenditure|\n",
      "+----+-----------------+\n",
      "|2018|             6054|\n",
      "|2019|             4038|\n",
      "|2020|             8080|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_format.withColumnRenamed(\"sum(year)\",\"Total Expenditure\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c6903-f253-4e55-ae60-fd712566f52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
